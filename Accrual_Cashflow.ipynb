{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83a9asPPa4h7",
        "outputId": "7349f4e5-aea1-4cdc-a094-c1d831ddb8ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "#Connect Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\", force_remount = True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import and install tools\n",
        "!pip install pandasql\n",
        "import os\n",
        "from datetime import datetime, timedelta\n",
        "from sklearn.model_selection import train_test_split\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from statsmodels.tsa.arima_model import ARIMA\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import math\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as sm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sqlite3 import connect\n",
        "from scipy.stats.mstats import winsorize, ks_2samp\n",
        "import seaborn as sns\n",
        "import pandasql as ps\n",
        "\n",
        "conn = connect(':memory:', timeout = 10)\n",
        "filePath = \"/content/gdrive/MyDrive/FinancePaperFIMA\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6baE7CK9bEiE",
        "outputId": "5d3595ad-621d-4e06-8cf7-82f2c30e3548"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandasql in /usr/local/lib/python3.9/dist-packages (0.7.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from pandasql) (1.22.4)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.9/dist-packages (from pandasql) (2.0.9)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from pandasql) (1.5.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->pandasql) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->pandasql) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from sqlalchemy->pandasql) (4.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/dist-packages (from sqlalchemy->pandasql) (2.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->pandasql) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import CRSP\n",
        "file = filePath + \"/CRSPMonthly1990Through2022.csv\"\n",
        "crsp1990To2022 = pd.read_csv(file)\n",
        "print(crsp1990To2022)\n",
        "print(crsp1990To2022.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0Kt59i9bFsD",
        "outputId": "b05fd665-15a1-42c2-943f-7a20f6945248"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-47-d35c1c9c03cc>:3: DtypeWarning: Columns (5,9,18,19,49,58) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  crsp1990To2022 = pd.read_csv(file)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         PERMNO      date  NAMEENDT  SHRCD  EXCHCD   SICCD    NCUSIP TICKER  \\\n",
            "0         10001  19900131       NaN   11.0     3.0    4920  39040610   GFGC   \n",
            "1         10001  19900228       NaN   11.0     3.0    4920  39040610   GFGC   \n",
            "2         10001  19900330       NaN   11.0     3.0    4920  39040610   GFGC   \n",
            "3         10001  19900430       NaN   11.0     3.0    4920  39040610   GFGC   \n",
            "4         10001  19900531       NaN   11.0     3.0    4920  39040610   GFGC   \n",
            "...         ...       ...       ...    ...     ...     ...       ...    ...   \n",
            "2975236   93436  20211130       NaN   11.0     3.0  9999.0  88160R10   TSLA   \n",
            "2975237   93436  20211231       NaN   11.0     3.0  9999.0  88160R10   TSLA   \n",
            "2975238   93436  20220131       NaN   11.0     3.0  9999.0  88160R10   TSLA   \n",
            "2975239   93436  20220228       NaN   11.0     3.0  9999.0  88160R10   TSLA   \n",
            "2975240   93436  20220331       NaN   11.0     3.0  9999.0  88160R10   TSLA   \n",
            "\n",
            "                     COMNAM SHRCLS  ... CFACSHR      ALTPRC SPREAD  \\\n",
            "0        GREAT FALLS GAS CO    NaN  ...     3.0    -9.93750  0.125   \n",
            "1        GREAT FALLS GAS CO    NaN  ...     3.0    -9.87500  0.250   \n",
            "2        GREAT FALLS GAS CO    NaN  ...     3.0    -9.87500  0.250   \n",
            "3        GREAT FALLS GAS CO    NaN  ...     3.0    -9.87500  0.250   \n",
            "4        GREAT FALLS GAS CO    NaN  ...     3.0     9.75000    NaN   \n",
            "...                     ...    ...  ...     ...         ...    ...   \n",
            "2975236           TESLA INC    NaN  ...     1.0  1144.76001    NaN   \n",
            "2975237           TESLA INC    NaN  ...     1.0  1056.78003    NaN   \n",
            "2975238           TESLA INC    NaN  ...     1.0   936.71997    NaN   \n",
            "2975239           TESLA INC    NaN  ...     1.0   870.42999    NaN   \n",
            "2975240           TESLA INC    NaN  ...     1.0  1077.59998    NaN   \n",
            "\n",
            "           ALTPRCDT       RETX    vwretd    vwretx    ewretd    ewretx  \\\n",
            "0        19900131.0  -0.018519 -0.070114 -0.071947 -0.046408 -0.048037   \n",
            "1        19900228.0  -0.006289  0.014900  0.010957  0.015434  0.013844   \n",
            "2        19900330.0   0.000000  0.024148  0.021626  0.021315  0.019445   \n",
            "3        19900430.0   0.000000 -0.028283 -0.030562 -0.028116 -0.029637   \n",
            "4        19900531.0  -0.012658  0.088935  0.084648  0.045673  0.043835   \n",
            "...             ...        ...       ...       ...       ...       ...   \n",
            "2975236  20211130.0   0.027612 -0.018347 -0.019703 -0.046540 -0.047915   \n",
            "2975237  20211231.0  -0.076855  0.033345  0.031577 -0.001760 -0.004799   \n",
            "2975238  20220131.0  -0.113609 -0.059754 -0.060500 -0.068191 -0.068869   \n",
            "2975239  20220228.0  -0.070768 -0.022027 -0.023310 -0.007667 -0.008624   \n",
            "2975240  20220331.0   0.238009  0.030696  0.029129  0.015438  0.013759   \n",
            "\n",
            "           sprtrn  \n",
            "0       -0.068817  \n",
            "1        0.008539  \n",
            "2        0.024255  \n",
            "3       -0.026887  \n",
            "4        0.091989  \n",
            "...           ...  \n",
            "2975236 -0.008334  \n",
            "2975237  0.043613  \n",
            "2975238 -0.052585  \n",
            "2975239 -0.031361  \n",
            "2975240  0.035773  \n",
            "\n",
            "[2975241 rows x 64 columns]\n",
            "Index(['PERMNO', 'date', 'NAMEENDT', 'SHRCD', 'EXCHCD', 'SICCD', 'NCUSIP',\n",
            "       'TICKER', 'COMNAM', 'SHRCLS', 'TSYMBOL', 'NAICS', 'PRIMEXCH', 'TRDSTAT',\n",
            "       'SECSTAT', 'PERMCO', 'ISSUNO', 'HEXCD', 'HSICCD', 'CUSIP', 'DCLRDT',\n",
            "       'DLAMT', 'DLPDT', 'DLSTCD', 'NEXTDT', 'PAYDT', 'RCRDDT', 'SHRFLG',\n",
            "       'HSICMG', 'HSICIG', 'DISTCD', 'DIVAMT', 'FACPR', 'FACSHR', 'ACPERM',\n",
            "       'ACCOMP', 'SHRENDDT', 'NWPERM', 'DLRETX', 'DLPRC', 'DLRET', 'TRTSCD',\n",
            "       'NMSIND', 'MMCNT', 'NSDINX', 'BIDLO', 'ASKHI', 'PRC', 'VOL', 'RET',\n",
            "       'BID', 'ASK', 'SHROUT', 'CFACPR', 'CFACSHR', 'ALTPRC', 'SPREAD',\n",
            "       'ALTPRCDT', 'RETX', 'vwretd', 'vwretx', 'ewretd', 'ewretx', 'sprtrn'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Parse relevant variables\n",
        "crsp1990To2022 = crsp1990To2022.filter(['TICKER', 'date', 'SHRCD', 'EXCHCD', 'SICCD', 'SHROUT', 'ALTPRC', 'RET', 'DLRET', 'DLSTCD'])\n",
        "\n",
        "#Change column names\n",
        "crsp1990To2022.columns = ['tic', 'date', 'shrcd', 'exchcd', 'siccd', 'shrout', 'altprc', 'ret', 'dlret', 'dlstcd']\n",
        "\n",
        "#Convert variable types\n",
        "crsp1990To2022['tic'] = crsp1990To2022['tic'].apply(str)\n",
        "crsp1990To2022['date'] = pd.to_datetime(crsp1990To2022['date'], format = '%Y%m%d')\n",
        "crsp1990To2022['shrcd'] = pd.to_numeric(crsp1990To2022['shrcd'], errors = 'coerce')\n",
        "crsp1990To2022['exchcd'] = pd.to_numeric(crsp1990To2022['exchcd'], errors = 'coerce')\n",
        "crsp1990To2022['siccd'] = pd.to_numeric(crsp1990To2022['siccd'], errors = 'coerce')\n",
        "crsp1990To2022['shrout'] = pd.to_numeric(crsp1990To2022['shrout'], errors = 'coerce')\n",
        "crsp1990To2022['altprc'] = pd.to_numeric(crsp1990To2022['altprc'], errors = 'coerce')\n",
        "crsp1990To2022['ret'] = pd.to_numeric(crsp1990To2022['ret'], errors = 'coerce')\n",
        "crsp1990To2022['dlret'] = pd.to_numeric(crsp1990To2022['dlret'], errors = 'coerce')\n",
        "crsp1990To2022['dlstcd'] = pd.to_numeric(crsp1990To2022['dlstcd'], errors = 'coerce')\n",
        "\n",
        "#Only keep dates after 2018\n",
        "crsp2018To2022 = crsp1990To2022[crsp1990To2022['date'] >= \"2018-01-01\"]\n",
        "\n",
        "#Only keep US based common stocks\n",
        "crsp2018To2022 = crsp2018To2022[(crsp2018To2022['shrcd'] == 10) | (crsp2018To2022['shrcd'] == 11)]\n",
        "\n",
        "#Only keep NYSE, AMEX, and NASDAQ\n",
        "crsp2018To2022 = crsp2018To2022[(crsp2018To2022['exchcd'] == 1) | (crsp2018To2022['exchcd'] == 2) | (crsp2018To2022['exchcd'] == 3) | (crsp2018To2022['exchcd'] == 31) | (crsp2018To2022['exchcd'] == 32) | (crsp2018To2022['exchcd'] == 33)]\n",
        "\n",
        "#convert SICCD to 2-digit level\n",
        "crsp2018To2022['siccd'] = np.floor(crsp2018To2022['siccd'] / 100)\n",
        "\n",
        "#Adjust delisting returns\n",
        "crsp2018To2022['ret_adj'] = \"\"\n",
        "for i in crsp2018To2022.index:\n",
        "  if (pd.isnull(crsp2018To2022['dlstcd'][i])) or (crsp2018To2022['dlstcd'][i] == 100):\n",
        "    crsp2018To2022['ret_adj'][i] = crsp2018To2022['ret'][i]\n",
        "  elif(pd.notnull(crsp2018To2022['dlstcd'][i])) and (pd.notnull(crsp2018To2022['dlret'][i])):\n",
        "    crsp2018To2022['ret_adj'][i] = crsp2018To2022['dlret'][i]\n",
        "  elif(551 <= crsp2018To2022['dlstcd'][i] <= 574) or (crsp2018To2022['dlstcd'][i] in [500, 520, 580, 584]):\n",
        "    crsp2018To2022['ret_adj'][i] = -0.3\n",
        "  else:\n",
        "    crsp2018To2022['ret_adj'][i] = -1\n",
        "\n",
        "crsp2018To2022.drop('dlret', inplace = True, axis = 1)\n",
        "crsp2018To2022.drop('dlstcd', inplace = True, axis = 1)\n",
        "\n",
        "#Calculate market value\n",
        "crsp2018To2022['market_value'] = np.abs(crsp2018To2022['altprc'] * crsp2018To2022['shrout'])\n",
        "\n",
        "#Add year and month columns\n",
        "crsp2018To2022['date'] = pd.to_datetime(crsp2018To2022['date'])\n",
        "crsp2018To2022['year'] = crsp2018To2022['date'].dt.year\n",
        "crsp2018To2022['month'] = crsp2018To2022['date'].dt.month\n",
        "\n",
        "#Sort DF\n",
        "crsp2018To2022 = crsp2018To2022.sort_values(by = ['tic', 'date'])\n",
        "\n",
        "#Add deciles based on market value at the start of the year\n",
        "g = crsp2018To2022.groupby(['year', 'tic'], as_index = False)['market_value'].first()\n",
        "g['size_quantile'] = g.groupby(['year'])['market_value'].rank(pct = True)\n",
        "g['size_decile'] = np.ceil(10 * g['size_quantile'])\n",
        "g.drop(['market_value', 'size_quantile'], inplace = True, axis = 1)\n",
        "crsp2018To2022 = crsp2018To2022.merge(g, on = ['year', 'tic'], how = 'left')\n",
        "\n",
        "#Drop missing values\n",
        "crsp2018To2022 = crsp2018To2022.dropna()\n",
        "\n",
        "#Reindex\n",
        "crsp2018To2022 = crsp2018To2022.reset_index()\n",
        "crsp2018To2022.drop('index', inplace = True, axis = 1)\n",
        "\n",
        "print(crsp2018To2022)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ytyex2uFbFpz",
        "outputId": "38718b84-b02a-461d-e29e-5c13dbab09b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-48-5f0c442aa3eb>:29: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  crsp2018To2022['siccd'] = np.floor(crsp2018To2022['siccd'] / 100)\n",
            "<ipython-input-48-5f0c442aa3eb>:32: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  crsp2018To2022['ret_adj'] = \"\"\n",
            "<ipython-input-48-5f0c442aa3eb>:35: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  crsp2018To2022['ret_adj'][i] = crsp2018To2022['ret'][i]\n",
            "<ipython-input-48-5f0c442aa3eb>:37: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  crsp2018To2022['ret_adj'][i] = crsp2018To2022['dlret'][i]\n",
            "<ipython-input-48-5f0c442aa3eb>:41: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  crsp2018To2022['ret_adj'][i] = -1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         tic       date  shrcd  exchcd  siccd    shrout  altprc       ret  \\\n",
            "0          A 2018-01-31   11.0     1.0   38.0  323018.0   73.43  0.096461   \n",
            "1          A 2018-02-28   11.0     1.0   38.0  322717.0   68.59 -0.065913   \n",
            "2          A 2018-03-29   11.0     1.0   38.0  322477.0   66.90 -0.024639   \n",
            "3          A 2018-04-30   11.0     1.0   38.0  322477.0   65.74 -0.015112   \n",
            "4          A 2018-05-31   11.0     1.0   38.0  319952.0   61.92 -0.058108   \n",
            "...      ...        ...    ...     ...    ...       ...     ...       ...   \n",
            "191199  ZYXI 2021-12-31   11.0     3.0   99.0   39738.0    9.97 -0.221094   \n",
            "191200  ZYXI 2022-01-31   11.0     3.0   99.0   43712.0    7.92 -0.116148   \n",
            "191201  ZYXI 2022-01-31   11.0     3.0   99.0   43712.0    7.92 -0.116148   \n",
            "191202  ZYXI 2022-02-28   11.0     3.0   99.0   43712.0    6.29 -0.205808   \n",
            "191203  ZYXI 2022-03-31   11.0     3.0   99.0   39784.0    6.23 -0.009539   \n",
            "\n",
            "         ret_adj  market_value  year  month  size_decile  \n",
            "0       0.096461   23719211.74  2018      1         10.0  \n",
            "1      -0.065913   22135159.03  2018      2         10.0  \n",
            "2      -0.024639   21573711.30  2018      3         10.0  \n",
            "3      -0.015112   21199637.98  2018      4         10.0  \n",
            "4      -0.058108   19811427.84  2018      5         10.0  \n",
            "...          ...           ...   ...    ...          ...  \n",
            "191199 -0.221094     396187.86  2021     12          5.0  \n",
            "191200 -0.116148     346199.04  2022      1          4.0  \n",
            "191201 -0.116148     346199.04  2022      1          4.0  \n",
            "191202 -0.205808     274948.48  2022      2          4.0  \n",
            "191203 -0.009539     247854.32  2022      3          4.0  \n",
            "\n",
            "[191204 rows x 13 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Export compustat for customer supplier\n",
        "\n",
        "tempCols = ['tic', 'datadate', 'sale', 'csho', 'prcc_c', 'prcc_f', 'conm', 'indfmt', 'datafmt']\n",
        "file = filePath + \"/CompustatAnnual1950to2022.csv\"\n",
        "tempDF = pd.read_csv(file, usecols = tempCols)[tempCols]\n",
        "tempDF = tempDF[tempDF['datadate'] >= 20180101]\n",
        "tempDF.to_csv(\"/content/gdrive/MyDrive/FinancePaperFIMA/compustat2018To2022.csv\")\n",
        "\n",
        "#Import Compustat CSV\n",
        "file = filePath + \"/CompustatAnnual1950to2022.csv\"\n",
        "columnsToUse = ['tic', 'datadate', 'fyear', 'indfmt', 'datafmt', 'che', 'act', 'lct', 'at', 'dp', 'ib', 'dlc', 'txp', 'oiadp']\n",
        "compustat1950To2022 = pd.read_csv(file, usecols = columnsToUse)[columnsToUse]\n",
        "print(compustat1950To2022)\n",
        "print(compustat1950To2022.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzalsWj3bFnV",
        "outputId": "db2992cd-d3b6-4d69-b672-e1864ae0bd51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          tic  datadate   fyear indfmt datafmt       che        act  \\\n",
            "0        AE.2  19611231  1961.0   INDL     STD       NaN        NaN   \n",
            "1        AE.2  19621231  1962.0   INDL     STD       NaN        NaN   \n",
            "2        AE.2  19631231  1963.0   INDL     STD       NaN      0.408   \n",
            "3        AE.2  19641231  1964.0   INDL     STD     0.269      0.718   \n",
            "4        AE.2  19651231  1965.0   INDL     STD     0.031      0.725   \n",
            "...       ...       ...     ...    ...     ...       ...        ...   \n",
            "591305  IVCGF  20201231  2020.0   INDL     STD   558.000  12100.000   \n",
            "591306  IVCGF  20211231  2021.0   INDL     STD  1020.181  12385.477   \n",
            "591307  DTRUY  20191231  2019.0   INDL     STD  6532.226  31890.187   \n",
            "591308  DTRUY  20201231  2020.0   INDL     STD  9012.671  30632.474   \n",
            "591309  DTRUY  20211231  2021.0   INDL     STD  8358.207  31787.117   \n",
            "\n",
            "              lct         at        dp        ib        dlc      txp     oiadp  \n",
            "0             NaN        NaN       NaN     0.050        NaN      NaN       NaN  \n",
            "1             NaN        NaN     0.040     0.120        NaN      NaN       NaN  \n",
            "2           0.322        NaN     0.046     0.003        NaN    0.000     0.000  \n",
            "3           0.267      1.416     0.053     0.039      0.088    0.007     0.074  \n",
            "4           0.623      2.310     0.082    -0.197      0.300    0.000    -0.242  \n",
            "...           ...        ...       ...       ...        ...      ...       ...  \n",
            "591305  13594.000  18841.000   991.000  -492.000   6205.000   78.000    67.000  \n",
            "591306        NaN  18834.114   895.075    59.141   6293.960   55.729   527.719  \n",
            "591307  25164.947  62131.888  2413.815  1942.498  13242.877  151.495  2579.898  \n",
            "591308  25743.429  60256.041  2644.617  -172.370  14229.582  125.360   154.290  \n",
            "591309  19725.777  62325.449  2035.813  2669.303   6231.408  276.370  1875.449  \n",
            "\n",
            "[591310 rows x 14 columns]\n",
            "Index(['tic', 'datadate', 'fyear', 'indfmt', 'datafmt', 'che', 'act', 'lct',\n",
            "       'at', 'dp', 'ib', 'dlc', 'txp', 'oiadp'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Clean compustat DF\n",
        "\n",
        "#Change column names\n",
        "compustat1950To2022.columns = ['tic', 'datadate', 'fyear', 'indfmt', 'datafmt', 'cash', 'ca', 'cl', 'ta', 'dep', 'ib', 'std', 'tp', 'oiadp']\n",
        "\n",
        "#Convert each column to correct variable types\n",
        "compustat1950To2022['tic'] = compustat1950To2022['tic'].apply(str) #firm identifier\n",
        "compustat1950To2022['datadate'] = pd.to_datetime(compustat1950To2022['datadate'], format = '%Y%m%d') #date of data\n",
        "compustat1950To2022['fyear'] = pd.to_numeric(compustat1950To2022['fyear'], errors = 'coerce') #fiscal year of data\n",
        "compustat1950To2022['indfmt'] = compustat1950To2022['indfmt'].apply(str) #industry format\n",
        "compustat1950To2022['datafmt'] = compustat1950To2022['datafmt'].apply(str) #data fmt\n",
        "compustat1950To2022['cash'] = pd.to_numeric(compustat1950To2022['cash'], errors = 'coerce') #cash and short-term investements\n",
        "compustat1950To2022['ca'] = pd.to_numeric(compustat1950To2022['ca'], errors = 'coerce') #current assets\n",
        "compustat1950To2022['cl'] = pd.to_numeric(compustat1950To2022['cl'], errors = 'coerce') #current liabilities\n",
        "compustat1950To2022['ta'] = pd.to_numeric(compustat1950To2022['ta'], errors = 'coerce') #total assets\n",
        "compustat1950To2022['dep'] = pd.to_numeric(compustat1950To2022['dep'], errors = 'coerce') #depreciation and amortization\n",
        "compustat1950To2022['ib'] = pd.to_numeric(compustat1950To2022['ib'], errors = 'coerce') #income before extraordinary items\n",
        "compustat1950To2022['std'] = pd.to_numeric(compustat1950To2022['std'], errors = 'coerce') #debt in current liabilities\n",
        "compustat1950To2022['tp'] = pd.to_numeric(compustat1950To2022['tp'], errors = 'coerce') #income taxes payable\n",
        "compustat1950To2022['oiadp'] = pd.to_numeric(compustat1950To2022['oiadp'], errors = 'coerce') #operating income after depreciation\n",
        "\n",
        "#Only keep data after 2017\n",
        "compustat2018To2022 = compustat1950To2022[compustat1950To2022['datadate'] >= \"2017-01-01\"]\n",
        "\n",
        "#Only keep correct formats\n",
        "compustat2018To2022 = compustat2018To2022[compustat2018To2022['indfmt'] == \"INDL\"]\n",
        "compustat2018To2022 = compustat2018To2022[compustat2018To2022['datafmt'] == \"STD\"]\n",
        "\n",
        "#Drop infinite/null values\n",
        "compustat2018To2022.replace([np.inf, -np.inf], np.nan, inplace = True)\n",
        "compustat2018To2022 = compustat2018To2022.dropna()\n",
        "\n",
        "#Reindex\n",
        "compustat2018To2022 = compustat2018To2022.reset_index()\n",
        "compustat2018To2022.drop('index', inplace = True, axis = 1)\n",
        "\n",
        "#Calculate change in variables\n",
        "compustat2018To2022['delta_cash'] = compustat2018To2022.groupby(['tic'])['cash'].diff()\n",
        "compustat2018To2022['delta_ca'] = compustat2018To2022.groupby(['tic'])['ca'].diff()\n",
        "compustat2018To2022['delta_cl'] = compustat2018To2022.groupby(['tic'])['cl'].diff()\n",
        "compustat2018To2022['delta_std'] = compustat2018To2022.groupby(['tic'])['std'].diff()\n",
        "compustat2018To2022['delta_tp'] = compustat2018To2022.groupby(['tic'])['tp'].diff()\n",
        "\n",
        "#Drop null values\n",
        "compustat2018To2022 = compustat2018To2022.dropna()\n",
        "\n",
        "#Calculate accruals\n",
        "compustat2018To2022['accruals'] = (compustat2018To2022['delta_ca'] - compustat2018To2022['delta_cash']) - (compustat2018To2022['delta_cl'] - compustat2018To2022['delta_std'] - compustat2018To2022['delta_tp']) - compustat2018To2022['dep']\n",
        "compustat2018To2022['accruals_subcomp_1'] = compustat2018To2022['delta_ca'] - compustat2018To2022['delta_cash']\n",
        "compustat2018To2022['accruals_subcomp_2'] = -(compustat2018To2022['delta_cl'] - compustat2018To2022['delta_std'] - compustat2018To2022['delta_tp'])\n",
        "compustat2018To2022['accruals_subcomp_3'] = -(compustat2018To2022['dep'])\n",
        "\n",
        "#Calculate total assets\n",
        "avgATDF = compustat2018To2022.groupby(['tic'], as_index = False)['ta'].mean()\n",
        "avgATDF.columns = ['tic', 'avg_at']\n",
        "compustat2018To2022 = compustat2018To2022.merge(avgATDF, on = 'tic', how = 'left')\n",
        "\n",
        "#Calculate earnings component\n",
        "compustat2018To2022['earnings_comp'] = compustat2018To2022['oiadp'] / compustat2018To2022['avg_at']\n",
        "\n",
        "#Calculate accruals component\n",
        "compustat2018To2022['accruals_comp'] = compustat2018To2022['accruals'] / compustat2018To2022['avg_at']\n",
        "\n",
        "#Calculate cash flow component\n",
        "compustat2018To2022['cash_flows_comp'] = compustat2018To2022['earnings_comp'] / compustat2018To2022['accruals_comp']\n",
        "\n",
        "#Standardize sub-components\n",
        "compustat2018To2022['accruals_subcomp_1'] /= compustat2018To2022['avg_at']\n",
        "compustat2018To2022['accruals_subcomp_2'] /= compustat2018To2022['avg_at']\n",
        "compustat2018To2022['accruals_subcomp_3'] /= compustat2018To2022['avg_at']\n",
        "#Drop infinite/null values\n",
        "compustat2018To2022.replace([np.inf, -np.inf], np.nan, inplace = True)\n",
        "compustat2018To2022 = compustat2018To2022.dropna()\n",
        "#Reindex\n",
        "compustat2018To2022 = compustat2018To2022.reset_index()\n",
        "compustat2018To2022.drop(['index'], inplace = True, axis = 1)\n",
        "print(compustat2018To2022)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9A4RN53UbFk1",
        "outputId": "aaef2e24-8d8e-488e-d5c1-337a82425db1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         tic   datadate   fyear indfmt datafmt      cash         ca  \\\n",
            "0        AIR 2018-05-31  2017.0   INDL     STD    41.600    942.700   \n",
            "1        AIR 2019-05-31  2018.0   INDL     STD    41.100    952.500   \n",
            "2        AIR 2020-05-31  2019.0   INDL     STD   424.700   1438.700   \n",
            "3        AIR 2021-05-31  2020.0   INDL     STD    60.200    937.000   \n",
            "4        AIR 2022-05-31  2021.0   INDL     STD    58.900   1007.200   \n",
            "...      ...        ...     ...    ...     ...       ...        ...   \n",
            "24301   KARO 2021-02-28  2020.0   INDL     STD    65.057     87.432   \n",
            "24302   KARO 2022-02-28  2021.0   INDL     STD    47.427     72.275   \n",
            "24303  IVCGF 2020-12-31  2020.0   INDL     STD   558.000  12100.000   \n",
            "24304  DTRUY 2020-12-31  2020.0   INDL     STD  9012.671  30632.474   \n",
            "24305  DTRUY 2021-12-31  2021.0   INDL     STD  8358.207  31787.117   \n",
            "\n",
            "              cl         ta       dep  ...  delta_std  delta_tp  accruals  \\\n",
            "0        333.300   1524.700    40.500  ...     -2.000   -12.300   -30.100   \n",
            "1        357.500   1517.200    42.800  ...      0.000     0.000   -56.700   \n",
            "2        383.100   2079.000    43.700  ...     13.700     0.000    47.000   \n",
            "3        336.800   1539.700    36.300  ...     -2.200     0.700  -128.700   \n",
            "4        348.200   1573.900    33.100  ...     -0.400    -0.700    25.900   \n",
            "...          ...        ...       ...  ...        ...       ...       ...   \n",
            "24301     94.504    192.079    26.276  ...      1.605     0.225   -97.462   \n",
            "24302     40.451    200.247    32.235  ...      0.341     0.964    25.596   \n",
            "24303  13594.000  18841.000   991.000  ...    644.000   -42.000  -955.000   \n",
            "24304  25743.429  60256.041  2644.617  ...    986.705   -26.135 -6000.687   \n",
            "24305  19725.777  62325.449  2035.813  ...  -7998.174   151.010 -2056.218   \n",
            "\n",
            "       accruals_subcomp_1  accruals_subcomp_2  accruals_subcomp_3     avg_at  \\\n",
            "0                0.013905           -0.007590           -0.024592   1646.900   \n",
            "1                0.006254           -0.014694           -0.025988   1646.900   \n",
            "2                0.062299           -0.007226           -0.026535   1646.900   \n",
            "3               -0.083308            0.027203           -0.022041   1646.900   \n",
            "4                0.043415           -0.007590           -0.020098   1646.900   \n",
            "...                   ...                 ...                 ...        ...   \n",
            "24301           -0.026106           -0.392736           -0.154602    169.959   \n",
            "24302            0.014551            0.325714           -0.189663    169.959   \n",
            "24303            0.023353           -0.021443           -0.052598  18841.000   \n",
            "24304           -0.060991            0.006234           -0.043149  61290.745   \n",
            "24305            0.029517           -0.029850           -0.033216  61290.745   \n",
            "\n",
            "       earnings_comp  accruals_comp  cash_flows_comp  \n",
            "0           0.052219      -0.018277        -2.857143  \n",
            "1           0.067217      -0.034428        -1.952381  \n",
            "2           0.064606       0.028538         2.263830  \n",
            "3           0.039772      -0.078147        -0.508936  \n",
            "4           0.070557       0.015727         4.486486  \n",
            "...              ...            ...              ...  \n",
            "24301       0.312181      -0.573444        -0.544397  \n",
            "24302       0.305485       0.150601         2.028442  \n",
            "24303       0.003556      -0.050687        -0.070157  \n",
            "24304       0.002517      -0.097905        -0.025712  \n",
            "24305       0.030599      -0.033549        -0.912087  \n",
            "\n",
            "[24306 rows x 27 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate mainDF with merged CRSP and Compustat\n",
        "crsp2018To2022.to_sql(\"crsp2018To2022\", conn, if_exists = 'replace')\n",
        "compustat2018To2022.to_sql(\"compustat2018To2022\", conn, if_exists = 'replace')\n",
        "query = '''\n",
        "        SELECT DISTINCT crsp2018To2022.*, compustat2018To2022.earnings_comp, compustat2018To2022.accruals_comp, compustat2018To2022.cash_flows_comp,\n",
        "        compustat2018To2022.accruals_subcomp_1, compustat2018To2022.accruals_subcomp_2, compustat2018To2022.accruals_subcomp_3\n",
        "        FROM crsp2018To2022\n",
        "        LEFT JOIN compustat2018To2022\n",
        "        ON crsp2018To2022.tic = compustat2018To2022.tic\n",
        "        AND crsp2018To2022.date = compustat2018To2022.datadate\n",
        "        '''\n",
        "\n",
        "mainDF = pd.read_sql(query, conn)\n",
        "mainDF.drop('index', inplace = True, axis = 1)\n",
        "print(mainDF)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1eSnBEubFih",
        "outputId": "2da649d5-9d50-4133-88ba-e09b7312f173"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         tic                 date  shrcd  exchcd  siccd    shrout  altprc  \\\n",
            "0          A  2018-01-31 00:00:00   11.0     1.0   38.0  323018.0   73.43   \n",
            "1          A  2018-02-28 00:00:00   11.0     1.0   38.0  322717.0   68.59   \n",
            "2          A  2018-03-29 00:00:00   11.0     1.0   38.0  322477.0   66.90   \n",
            "3          A  2018-04-30 00:00:00   11.0     1.0   38.0  322477.0   65.74   \n",
            "4          A  2018-05-31 00:00:00   11.0     1.0   38.0  319952.0   61.92   \n",
            "...      ...                  ...    ...     ...    ...       ...     ...   \n",
            "191199  ZYXI  2021-12-31 00:00:00   11.0     3.0   99.0   39738.0    9.97   \n",
            "191200  ZYXI  2022-01-31 00:00:00   11.0     3.0   99.0   43712.0    7.92   \n",
            "191201  ZYXI  2022-01-31 00:00:00   11.0     3.0   99.0   43712.0    7.92   \n",
            "191202  ZYXI  2022-02-28 00:00:00   11.0     3.0   99.0   43712.0    6.29   \n",
            "191203  ZYXI  2022-03-31 00:00:00   11.0     3.0   99.0   39784.0    6.23   \n",
            "\n",
            "             ret    ret_adj  market_value  year  month  size_decile  \\\n",
            "0       0.096461   0.096461   23719211.74  2018      1         10.0   \n",
            "1      -0.065913  -0.065913   22135159.03  2018      2         10.0   \n",
            "2      -0.024639  -0.024639   21573711.30  2018      3         10.0   \n",
            "3      -0.015112  -0.015112   21199637.98  2018      4         10.0   \n",
            "4      -0.058108  -0.058108   19811427.84  2018      5         10.0   \n",
            "...          ...        ...           ...   ...    ...          ...   \n",
            "191199 -0.221094  -0.221094     396187.86  2021     12          5.0   \n",
            "191200 -0.116148  -0.116148     346199.04  2022      1          4.0   \n",
            "191201 -0.116148  -0.116148     346199.04  2022      1          4.0   \n",
            "191202 -0.205808  -0.205808     274948.48  2022      2          4.0   \n",
            "191203 -0.009539  -0.009539     247854.32  2022      3          4.0   \n",
            "\n",
            "        earnings_comp  accruals_comp  cash_flows_comp  accruals_subcomp_1  \\\n",
            "0                 NaN            NaN              NaN                 NaN   \n",
            "1                 NaN            NaN              NaN                 NaN   \n",
            "2                 NaN            NaN              NaN                 NaN   \n",
            "3                 NaN            NaN              NaN                 NaN   \n",
            "4                 NaN            NaN              NaN                 NaN   \n",
            "...               ...            ...              ...                 ...   \n",
            "191199       0.357985       0.150214         2.383165            0.259726   \n",
            "191200            NaN            NaN              NaN                 NaN   \n",
            "191201            NaN            NaN              NaN                 NaN   \n",
            "191202            NaN            NaN              NaN                 NaN   \n",
            "191203            NaN            NaN              NaN                 NaN   \n",
            "\n",
            "        accruals_subcomp_2  accruals_subcomp_3  \n",
            "0                      NaN                 NaN  \n",
            "1                      NaN                 NaN  \n",
            "2                      NaN                 NaN  \n",
            "3                      NaN                 NaN  \n",
            "4                      NaN                 NaN  \n",
            "...                    ...                 ...  \n",
            "191199           -0.072922           -0.036589  \n",
            "191200                 NaN                 NaN  \n",
            "191201                 NaN                 NaN  \n",
            "191202                 NaN                 NaN  \n",
            "191203                 NaN                 NaN  \n",
            "\n",
            "[191204 rows x 19 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import Fama French\n",
        "\n",
        "file = filePath + \"/F-F_Research_Data_5_Factors.csv\"\n",
        "ffDF = pd.read_csv(file)\n",
        "print(ffDF)\n",
        "print(ffDF.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlDL8HOIbFgV",
        "outputId": "e8b719cb-f254-4dc4-c505-02a819bb49e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Date  Mkt_RF   SMB    HML   RMW   CMA    RF\n",
            "0    196307   -0.39 -0.44  -0.89  0.68 -1.23  0.27\n",
            "1    196308    5.07 -0.75   1.68  0.36 -0.34  0.25\n",
            "2    196309   -1.57 -0.55   0.08 -0.71  0.29  0.27\n",
            "3    196310    2.53 -1.37  -0.14  2.80 -2.02  0.29\n",
            "4    196311   -0.85 -0.89   1.81 -0.51  2.31  0.27\n",
            "..      ...     ...   ...    ...   ...   ...   ...\n",
            "702  202201   -6.25 -3.95  12.74  0.73  7.73  0.00\n",
            "703  202202   -2.29  2.90   3.09 -2.12  2.99  0.00\n",
            "704  202203    3.06 -2.14  -1.82 -1.32  3.24  0.00\n",
            "705  202204   -9.45 -0.38   6.16  3.51  5.87  0.00\n",
            "706  202205   -0.34  0.02   8.38  1.61  3.82  0.03\n",
            "\n",
            "[707 rows x 7 columns]\n",
            "Index(['Date', 'Mkt_RF', 'SMB', 'HML', 'RMW', 'CMA', 'RF'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Clean FF Dataframe\n",
        "\n",
        "#Change columns names\n",
        "ffDF.columns = ['date', 'rm_minus_rf', 'smb', 'hml', 'rmw', 'cma', 'rf']\n",
        "\n",
        "#Add month and year columns\n",
        "ffDF['year'] = \"\"\n",
        "ffDF['month'] = \"\"\n",
        "for i in ffDF.index:\n",
        "  ffDF['year'][i] = int(str(ffDF['date'][i])[0:4]) #take first 4 digits of date (year)\n",
        "  ffDF['month'][i] = int(str(ffDF['date'][i])[-2] + str(ffDF['date'][i])[-1]) #take last two digits of date (month)\n",
        "\n",
        "#Change values to decimal\n",
        "ffDF['rm_minus_rf'] /= 100\n",
        "ffDF['smb'] /= 100\n",
        "ffDF['hml'] /= 100\n",
        "ffDF['rmw'] /= 100\n",
        "ffDF['cma'] /= 100\n",
        "ffDF['rf'] /= 100\n",
        "\n",
        "#Only keep dates after 2018\n",
        "ffDF = ffDF[ffDF['date'] >= 201801]\n",
        "\n",
        "#Reindex\n",
        "ffDF = ffDF.reset_index()\n",
        "ffDF.drop('index', inplace = True, axis = 1)\n",
        "\n",
        "#Calculate annual market return - risk free rate\n",
        "annualRmMinusRf = pd.DataFrame(index = [2018, 2019, 2020, 2021], columns = ['year', 'annual_rm_minus_rf'])\n",
        "annualRmMinusRf['year'] = annualRmMinusRf.index\n",
        "tempDF = ffDF.loc[0:11]\n",
        "tempDF['rm_minus_rf_compounded'] = (1 + tempDF['rm_minus_rf']).cumprod() - 1\n",
        "annualRmMinusRf['annual_rm_minus_rf'][2018] = tempDF['rm_minus_rf_compounded'][11]\n",
        "tempDF = ffDF.loc[12:23]\n",
        "tempDF['rm_minus_rf_compounded'] = (1 + tempDF['rm_minus_rf']).cumprod() - 1\n",
        "annualRmMinusRf['annual_rm_minus_rf'][2019] = tempDF['rm_minus_rf_compounded'][23]\n",
        "tempDF = ffDF.loc[24:35]\n",
        "tempDF['rm_minus_rf_compounded'] = (1 + tempDF['rm_minus_rf']).cumprod() - 1\n",
        "annualRmMinusRf['annual_rm_minus_rf'][2020] = tempDF['rm_minus_rf_compounded'][35]\n",
        "tempDF = ffDF.loc[36:47]\n",
        "tempDF['rm_minus_rf_compounded'] = (1 + tempDF['rm_minus_rf']).cumprod() - 1\n",
        "annualRmMinusRf['annual_rm_minus_rf'][2021] = tempDF['rm_minus_rf_compounded'][47]\n",
        "\n",
        "#Left join relevant FF (risk-free rate) data into main DF\n",
        "mainDF.to_sql(\"mainDF\", conn, if_exists = 'replace')\n",
        "ffDF.to_sql(\"ffDF\", conn, if_exists = 'replace')\n",
        "query = '''\n",
        "        SELECT DISTINCT mainDF.*, ffDF.rf, ffDF.rm_minus_rf\n",
        "        FROM mainDF\n",
        "        LEFT JOIN ffDF\n",
        "        ON mainDF.year = ffDF.year\n",
        "        AND mainDF.month = ffDF.month\n",
        "        '''\n",
        "mainDF = pd.read_sql(query, conn)\n",
        "mainDF['date'] = pd.to_datetime(mainDF['date'])\n",
        "mainDF['ret'] = pd.to_numeric(mainDF['ret'], errors = 'coerce')\n",
        "mainDF['ret_adj'] = pd.to_numeric(mainDF['ret_adj'], errors = 'coerce')\n",
        "mainDF['size_decile'] = pd.to_numeric(mainDF['size_decile'], errors = 'coerce')\n",
        "mainDF['ret_minus_rf'] = mainDF['ret_adj'] - mainDF['rf']\n",
        "\n",
        "#Add abnormal return data\n",
        "g = mainDF.groupby(['year', 'month', 'size_decile'], as_index = False).apply(lambda x: np.average(x['ret_adj']))\n",
        "g.columns = ['year', 'month', 'size_decile', 'avg_ret_on_size_decile']\n",
        "mainDF = mainDF.merge(g, on = ['year', 'month', 'size_decile'], how = 'left')\n",
        "mainDF['abn_ret'] = mainDF['ret_adj'] - mainDF['avg_ret_on_size_decile']\n",
        "mainDF.drop('index', inplace = True, axis = 1)\n",
        "mainDF.reset_index()\n",
        "mainDF.dropna()\n",
        "#Store mainDF\n",
        "tempMain = mainDF\n",
        "\n",
        "print(mainDF)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cePT2DB1bFdv",
        "outputId": "006e0770-681a-4b51-d0d9-e86392162dfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-53-237a12b801d3>:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ffDF['year'][i] = int(str(ffDF['date'][i])[0:4]) #take first 4 digits of date (year)\n",
            "<ipython-input-53-237a12b801d3>:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ffDF['month'][i] = int(str(ffDF['date'][i])[-2] + str(ffDF['date'][i])[-1]) #take last two digits of date (month)\n",
            "<ipython-input-53-237a12b801d3>:32: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  tempDF['rm_minus_rf_compounded'] = (1 + tempDF['rm_minus_rf']).cumprod() - 1\n",
            "<ipython-input-53-237a12b801d3>:33: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  annualRmMinusRf['annual_rm_minus_rf'][2018] = tempDF['rm_minus_rf_compounded'][11]\n",
            "<ipython-input-53-237a12b801d3>:35: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  tempDF['rm_minus_rf_compounded'] = (1 + tempDF['rm_minus_rf']).cumprod() - 1\n",
            "<ipython-input-53-237a12b801d3>:36: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  annualRmMinusRf['annual_rm_minus_rf'][2019] = tempDF['rm_minus_rf_compounded'][23]\n",
            "<ipython-input-53-237a12b801d3>:38: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  tempDF['rm_minus_rf_compounded'] = (1 + tempDF['rm_minus_rf']).cumprod() - 1\n",
            "<ipython-input-53-237a12b801d3>:39: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  annualRmMinusRf['annual_rm_minus_rf'][2020] = tempDF['rm_minus_rf_compounded'][35]\n",
            "<ipython-input-53-237a12b801d3>:41: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  tempDF['rm_minus_rf_compounded'] = (1 + tempDF['rm_minus_rf']).cumprod() - 1\n",
            "<ipython-input-53-237a12b801d3>:42: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  annualRmMinusRf['annual_rm_minus_rf'][2021] = tempDF['rm_minus_rf_compounded'][47]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         tic       date  shrcd  exchcd  siccd    shrout  altprc       ret  \\\n",
            "0          A 2018-01-31   11.0     1.0   38.0  323018.0   73.43  0.096461   \n",
            "1          A 2018-02-28   11.0     1.0   38.0  322717.0   68.59 -0.065913   \n",
            "2          A 2018-03-29   11.0     1.0   38.0  322477.0   66.90 -0.024639   \n",
            "3          A 2018-04-30   11.0     1.0   38.0  322477.0   65.74 -0.015112   \n",
            "4          A 2018-05-31   11.0     1.0   38.0  319952.0   61.92 -0.058108   \n",
            "...      ...        ...    ...     ...    ...       ...     ...       ...   \n",
            "191199  ZYXI 2021-12-31   11.0     3.0   99.0   39738.0    9.97 -0.221094   \n",
            "191200  ZYXI 2022-01-31   11.0     3.0   99.0   43712.0    7.92 -0.116148   \n",
            "191201  ZYXI 2022-01-31   11.0     3.0   99.0   43712.0    7.92 -0.116148   \n",
            "191202  ZYXI 2022-02-28   11.0     3.0   99.0   43712.0    6.29 -0.205808   \n",
            "191203  ZYXI 2022-03-31   11.0     3.0   99.0   39784.0    6.23 -0.009539   \n",
            "\n",
            "         ret_adj  market_value  ...  accruals_comp  cash_flows_comp  \\\n",
            "0       0.096461   23719211.74  ...            NaN              NaN   \n",
            "1      -0.065913   22135159.03  ...            NaN              NaN   \n",
            "2      -0.024639   21573711.30  ...            NaN              NaN   \n",
            "3      -0.015112   21199637.98  ...            NaN              NaN   \n",
            "4      -0.058108   19811427.84  ...            NaN              NaN   \n",
            "...          ...           ...  ...            ...              ...   \n",
            "191199 -0.221094     396187.86  ...       0.150214         2.383165   \n",
            "191200 -0.116148     346199.04  ...            NaN              NaN   \n",
            "191201 -0.116148     346199.04  ...            NaN              NaN   \n",
            "191202 -0.205808     274948.48  ...            NaN              NaN   \n",
            "191203 -0.009539     247854.32  ...            NaN              NaN   \n",
            "\n",
            "        accruals_subcomp_1  accruals_subcomp_2  accruals_subcomp_3      rf  \\\n",
            "0                      NaN                 NaN                 NaN  0.0011   \n",
            "1                      NaN                 NaN                 NaN  0.0011   \n",
            "2                      NaN                 NaN                 NaN  0.0012   \n",
            "3                      NaN                 NaN                 NaN  0.0014   \n",
            "4                      NaN                 NaN                 NaN  0.0014   \n",
            "...                    ...                 ...                 ...     ...   \n",
            "191199            0.259726           -0.072922           -0.036589  0.0001   \n",
            "191200                 NaN                 NaN                 NaN  0.0000   \n",
            "191201                 NaN                 NaN                 NaN  0.0000   \n",
            "191202                 NaN                 NaN                 NaN  0.0000   \n",
            "191203                 NaN                 NaN                 NaN  0.0000   \n",
            "\n",
            "        rm_minus_rf  ret_minus_rf  avg_ret_on_size_decile   abn_ret  \n",
            "0            0.0558      0.095361                0.057790  0.038671  \n",
            "1           -0.0365     -0.067013               -0.037691 -0.028222  \n",
            "2           -0.0235     -0.025839               -0.011748 -0.012891  \n",
            "3            0.0029     -0.016512                0.002206 -0.017318  \n",
            "4            0.0265     -0.059508                0.016106 -0.074214  \n",
            "...             ...           ...                     ...       ...  \n",
            "191199       0.0310     -0.221194               -0.018886 -0.202208  \n",
            "191200      -0.0625     -0.116148               -0.067249 -0.048899  \n",
            "191201      -0.0625     -0.116148               -0.067249 -0.048899  \n",
            "191202      -0.0229     -0.205808               -0.002638 -0.203170  \n",
            "191203       0.0306     -0.009539               -0.001448 -0.008091  \n",
            "\n",
            "[191204 rows x 24 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Replicate Table 1A\n",
        "\n",
        "mainDF = tempMain\n",
        "\n",
        "#Generate DF with non-null components (end of fiscal year data)\n",
        "mainOnFYearEnd = mainDF.dropna()\n",
        "mainOnFYearEnd['accruals_comp_quantile'] = mainOnFYearEnd['accruals_comp'].rank(pct = True)\n",
        "mainOnFYearEnd['accruals_comp_decile'] = np.ceil(mainOnFYearEnd['accruals_comp_quantile'] * 10)\n",
        "\n",
        "#Generate data for firms with December fiscal-year ends (for CAPM regressions)\n",
        "mainOnFYearEndDecOnly = mainOnFYearEnd[mainOnFYearEnd['month'] == 12]\n",
        "\n",
        "#Generate summary statistics (Table 1A)\n",
        "table1A = pd.DataFrame(index = ['accruals_mean', 'accruals_median', 'cash_flows_mean', 'cash_flows_median', 'earnings_mean', 'earnings_median'], columns = range(1, 11))\n",
        "for i in table1A.columns:\n",
        "  tempDF = mainOnFYearEnd[mainOnFYearEnd['accruals_comp_decile'] == i]\n",
        "  table1A[i]['accruals_mean'] = tempDF['accruals_comp'].mean()\n",
        "  table1A[i]['accruals_median'] = tempDF['accruals_comp'].median()\n",
        "  table1A[i]['cash_flows_mean'] = tempDF['cash_flows_comp'].mean()\n",
        "  table1A[i]['cash_flows_median'] = tempDF['cash_flows_comp'].median()\n",
        "  table1A[i]['earnings_mean'] = tempDF['earnings_comp'].mean()\n",
        "  table1A[i]['earnings_median'] = tempDF['earnings_comp'].median()\n",
        "\n",
        "print(table1A)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCeIbNurbFbn",
        "outputId": "e1c6ae95-05ee-4ef9-8f44-bb56ab2e8736"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                         1         2         3         4         5         6   \\\n",
            "accruals_mean     -0.189894 -0.089031 -0.063193 -0.047544 -0.035427 -0.024555   \n",
            "accruals_median   -0.147419 -0.088124 -0.062777 -0.047807 -0.035563 -0.024597   \n",
            "cash_flows_mean     1.08581  0.849031  0.433792  0.341183  0.875631  1.392742   \n",
            "cash_flows_median  0.332357 -0.252192 -0.632714 -1.019276 -1.349501 -1.995764   \n",
            "earnings_mean     -0.219157  -0.07587 -0.027436  -0.01622 -0.030996 -0.032371   \n",
            "earnings_median   -0.056139  0.022564  0.040335  0.048434  0.047548  0.047679   \n",
            "\n",
            "                         7                     8         9         10  \n",
            "accruals_mean      -0.01346              -0.00034  0.021679  0.142687  \n",
            "accruals_median   -0.013717             -0.000742  0.020226  0.094279  \n",
            "cash_flows_mean    3.395969  2036100260239.764404 -7.067792 -2.116516  \n",
            "cash_flows_median -2.766586             -0.525362 -0.461314 -0.542677  \n",
            "earnings_mean     -0.040971             -0.075646  -0.12773 -0.233787  \n",
            "earnings_median    0.039999              0.014194 -0.009105 -0.076039  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-54-56cd44d41d91>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  mainOnFYearEnd['accruals_comp_quantile'] = mainOnFYearEnd['accruals_comp'].rank(pct = True)\n",
            "<ipython-input-54-56cd44d41d91>:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  mainOnFYearEnd['accruals_comp_decile'] = np.ceil(mainOnFYearEnd['accruals_comp_quantile'] * 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Replicate Table 1B\n",
        "\n",
        "mainDF = tempMain\n",
        "\n",
        "#Initialize empty DataFrames\n",
        "table1B = pd.DataFrame(columns = range(1, 11))\n",
        "annualRetMinusRf = pd.DataFrame(index = range(2018,2022), columns = range(1, 11))\n",
        "for i in annualRetMinusRf.index:\n",
        "  for j in annualRetMinusRf.columns:\n",
        "    annualRetMinusRf[j][i] = []\n",
        "\n",
        "sizeOfPortfolios = pd.DataFrame(index = ['size', 'size_mean', 'size_median'], columns = range(1, 11))\n",
        "for i in sizeOfPortfolios.index:\n",
        "  for j in sizeOfPortfolios.columns:\n",
        "    sizeOfPortfolios[j][i] = []\n",
        "\n",
        "#Calculate compound ret - rf\n",
        "for i in table1B.columns:\n",
        "  tempDF = mainOnFYearEndDecOnly[mainOnFYearEndDecOnly['accruals_comp_decile'] == i]\n",
        "  for j in tempDF.index:\n",
        "    if((j - 11) in mainDF.index) and (mainDF['tic'][j - 11] == tempDF['tic'][j]): #check if index exists and is the same firm as current data\n",
        "      tempDF2 = mainDF.loc[(j - 11) : j]\n",
        "      tempDF2['ret_minus_rf_compounded'] = (1 + tempDF2['ret_minus_rf']).cumprod() - 1\n",
        "      yearOfData = tempDF2['year'][j]\n",
        "      annualRetMinusRf[i][yearOfData].append(tempDF2['ret_minus_rf_compounded'][j]) #add last count of compounded data to annual ret minus Rf data\n",
        "      sizeOfPortfolios[i]['size'].append(np.log(tempDF2['market_value'][j]))\n",
        "\n",
        "#Take average for each portfolio\n",
        "for i in annualRetMinusRf.index:\n",
        "  for j in annualRetMinusRf.columns:\n",
        "    annualRetMinusRf[j][i] = np.average(annualRetMinusRf[j][i])\n",
        "\n",
        "for j in sizeOfPortfolios.columns:\n",
        "  sizeOfPortfolios[j]['size_mean'] = np.average(sizeOfPortfolios[j]['size'])\n",
        "  sizeOfPortfolios[j]['size_median'] = np.median(sizeOfPortfolios[j]['size'])\n",
        "\n",
        "sizeOfPortfolios.drop('size', inplace = True, axis = 0)\n",
        "annualRetMinusRf['year'] = annualRetMinusRf.index\n",
        "print(sizeOfPortfolios)\n"
      ],
      "metadata": {
        "id": "jynpkd3GbFWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate DataFrame for Table 1B Regressions\n",
        "dataForTable1BReg = annualRetMinusRf.merge(annualRmMinusRf, on = 'year', how = 'left')\n",
        "dataForTable1BReg = dataForTable1BReg.astype(float)\n",
        "\n",
        "#Run regressions to get alpha and beta\n",
        "for i in range(1, 11):\n",
        "  tempDF = dataForTable1BReg.filter([i, 'annual_rm_minus_rf'])\n",
        "  tempDF.columns = ['current_decile_data', 'annual_rm_minus_rf']\n",
        "  tempReg = sm.ols(formula = \"current_decile_data ~ annual_rm_minus_rf\", data = tempDF).fit()\n",
        "  tempRegSummary = tempReg.summary()\n",
        "  print(\"Accruals decile = \" + str(i) + \":\")\n",
        "  print(tempRegSummary)"
      ],
      "metadata": {
        "id": "JtvkP1XxbFT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Replicate Table 1C\n",
        "\n",
        "mainDF = tempMain\n",
        "\n",
        "#Generate DF for Table 1C\n",
        "table1C = pd.DataFrame(index = ['current_asset_mean', 'current_asset_median', 'current_liability_mean', 'current_liability_median', 'depreciation_expense_mean', 'deprecation_expense_median'], columns = range(1,11))\n",
        "for i in table1C.columns:\n",
        "  tempDF = mainOnFYearEnd[mainOnFYearEnd['accruals_comp_decile'] == i]\n",
        "  table1C[i]['current_asset_mean'] = tempDF['accruals_subcomp_1'].mean()\n",
        "  table1C[i]['current_asset_median'] = tempDF['accruals_subcomp_1'].median()\n",
        "  table1C[i]['current_liability_mean'] = tempDF['accruals_subcomp_2'].mean()\n",
        "  table1C[i]['current_liability_median'] = tempDF['accruals_subcomp_2'].median()\n",
        "  table1C[i]['depreciation_expense_mean'] = tempDF['accruals_subcomp_3'].mean()\n",
        "  table1C[i]['depreciation_expense_median'] = tempDF['accruals_subcomp_3'].median()\n",
        "print(table1C)"
      ],
      "metadata": {
        "id": "Cdam6azYbFRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Replicate Table 2\n",
        "\n",
        "#Regenerate mainOnFYearEnd (to allow us to rerun the same code block for debugging)\n",
        "mainDF = tempMain\n",
        "mainOnFYearEnd = mainDF.dropna()\n",
        "mainOnFYearEnd['accruals_comp_quantile'] = mainOnFYearEnd['accruals_comp'].rank(pct = True)\n",
        "mainOnFYearEnd['accruals_comp_decile'] = np.ceil(mainOnFYearEnd['accruals_comp_quantile'] * 10)\n",
        "mainOnFYearEnd['earnings_comp_quantile'] = mainOnFYearEnd['earnings_comp'].rank(pct = True)\n",
        "mainOnFYearEnd['earnings_comp_decile'] = np.ceil(mainOnFYearEnd['earnings_comp_quantile'] * 10)\n",
        "mainOnFYearEnd['cash_flows_comp_quantile'] = mainOnFYearEnd['cash_flows_comp'].rank(pct = True)\n",
        "mainOnFYearEnd['cash_flows_comp_decile'] = np.ceil(mainOnFYearEnd['cash_flows_comp_quantile'] * 10)\n",
        "\n",
        "#Generate column for next year's earnings component and accruals decile\n",
        "mainOnFYearEnd['accruals_comp_next_year'] = mainOnFYearEnd.groupby(['tic'])['accruals_comp'].shift(-1)\n",
        "mainOnFYearEnd['earnings_comp_next_year'] = mainOnFYearEnd.groupby(['tic'])['earnings_comp'].shift(-1)\n",
        "mainOnFYearEnd['cash_flows_comp_next_year'] = mainOnFYearEnd.groupby(['tic'])['cash_flows_comp'].shift(-1)\n",
        "mainOnFYearEnd['accruals_comp_decile_next_year'] = mainOnFYearEnd.groupby(['tic'])['accruals_comp_decile'].shift(-1)\n",
        "mainOnFYearEnd['earnings_comp_decile_next_year'] = mainOnFYearEnd.groupby(['tic'])['earnings_comp_decile'].shift(-1)\n",
        "mainOnFYearEnd['cash_flows_comp_decile_next_year'] = mainOnFYearEnd.groupby(['tic'])['cash_flows_comp_decile'].shift(-1)\n",
        "\n",
        "#Generate DF for table 2 regressions (drops most recent year: no available next-year data)\n",
        "dataForTable2Reg = mainOnFYearEnd.dropna()\n",
        "\n",
        "#Run regressions\n",
        "table2AReg = sm.ols(formula = \"earnings_comp_next_year ~ earnings_comp\", data = dataForTable2Reg).fit()\n",
        "table2ARegSummary = table2AReg.summary()\n",
        "table2BReg = sm.ols(formula = \"earnings_comp_decile_next_year ~ earnings_comp_decile\", data = dataForTable2Reg).fit()\n",
        "table2BRegSummary = table2BReg.summary()\n",
        "\n",
        "#Run regressions for firms grouped by industry codes\n",
        "alpha0DistTable2A = []\n",
        "alpha0DistTable2B = []\n",
        "alpha1DistTable2A = []\n",
        "alpha1DistTable2B = []\n",
        "\n",
        "for i in dataForTable2Reg['siccd'].unique():\n",
        "  tempDF = dataForTable2Reg[dataForTable2Reg['siccd'] == i]\n",
        "  regA = sm.ols(formula = \"earnings_comp_next_year ~ earnings_comp\", data = tempDF).fit()\n",
        "  alpha0DistTable2A.append(regA.params[0])\n",
        "  alpha1DistTable2A.append(regA.params[1])\n",
        "  regB = sm.ols(formula = \"earnings_comp_decile_next_year ~ earnings_comp_decile\", data = tempDF).fit()\n",
        "  alpha0DistTable2B.append(regB.params[0])\n",
        "  alpha1DistTable2B.append(regB.params[1])\n",
        "\n",
        "#Print Table 2A results\n",
        "print(\"Table 2A\")\n",
        "print(\"Pooled Regressions\")\n",
        "print(table2ARegSummary)\n",
        "print(\"Industry Level Regressions\")\n",
        "print(\"Mean - alpha_0: \" + str(np.average(alpha0DistTable2A)) + \" alpha_1: \" + str(np.average(alpha1DistTable2A)))\n",
        "print(\"Q1 - alpha_0: \" + str(np.quantile(alpha0DistTable2A, 0.25)) + \" alpha_1: \" + str(np.quantile(alpha1DistTable2A, 0.25)))\n",
        "print(\"Median - alpha_0: \" + str(np.median(alpha0DistTable2A)) + \" alpha_1: \" + str(np.median(alpha1DistTable2A)))\n",
        "print(\"Q3 - alpha_0: \" + str(np.quantile(alpha0DistTable2A, 0.75)) + \" alpha_1: \" + str(np.quantile(alpha1DistTable2A, 0.75)))\n",
        "\n",
        "#Print Table 2B Results\n",
        "print(\"Table 2B\")\n",
        "print(\"Pooled Regressions\")\n",
        "print(table2BRegSummary)\n",
        "print(\"Industry Level Regressions\")\n",
        "print(\"Mean - alpha_0: \" + str(np.average(alpha0DistTable2B)) + \" alpha_1: \" + str(np.average(alpha1DistTable2B)))\n",
        "print(\"Q1 - alpha_0: \" + str(np.quantile(alpha0DistTable2B, 0.25)) + \" alpha_1: \" + str(np.quantile(alpha1DistTable2B, 0.25)))\n",
        "print(\"Median - alpha_0: \" + str(np.median(alpha0DistTable2B)) + \" alpha_1: \" + str(np.median(alpha1DistTable2B)))\n",
        "print(\"Q3 - alpha_0: \" + str(np.quantile(alpha0DistTable2B, 0.75)) + \" alpha_1: \" + str(np.quantile(alpha1DistTable2B, 0.75)))"
      ],
      "metadata": {
        "id": "LnkIKHmpbFPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Store mainOnFYearEnd for future use\n",
        "tempMainOnFYearEnd = mainOnFYearEnd\n",
        "\n",
        "#Replicate Table 3\n",
        "dataForTable3Reg = dataForTable2Reg\n",
        "\n",
        "#Run Regressions\n",
        "table3AReg = sm.ols(formula = \"earnings_comp_next_year ~ accruals_comp + cash_flows_comp\", data = dataForTable3Reg).fit()\n",
        "table3ARegSummary = table3AReg.summary()\n",
        "table3BReg = sm.ols(formula =\"earnings_comp_decile_next_year ~ accruals_comp_decile + cash_flows_comp_decile\", data = dataForTable3Reg).fit()\n",
        "table3BRegSummary = table3BReg.summary()\n",
        "\n",
        "#Run regressions for firms grouped by industry codes\n",
        "gamma0DistTable3A = []\n",
        "gamma1DistTable3A = []\n",
        "gamma2DistTable3A = []\n",
        "gamma0DistTable3B = []\n",
        "gamma1DistTable3B = []\n",
        "gamma2DistTable3B = []\n",
        "\n",
        "for i in dataForTable3Reg['siccd'].unique():\n",
        "  tempDF = dataForTable3Reg[dataForTable3Reg['siccd'] == i]\n",
        "  regA = sm.ols(formula = \"earnings_comp_next_year ~ accruals_comp + cash_flows_comp\", data = tempDF).fit()\n",
        "  gamma0DistTable3A.append(regA.params[0])\n",
        "  gamma1DistTable3A.append(regA.params[1])\n",
        "  gamma2DistTable3A.append(regA.params[2])\n",
        "  regB = sm.ols(formula = \"earnings_comp_decile_next_year ~ accruals_comp_decile + cash_flows_comp_decile\", data = tempDF).fit()\n",
        "  gamma0DistTable3B.append(regB.params[0])\n",
        "  gamma1DistTable3B.append(regB.params[1])\n",
        "  gamma2DistTable3B.append(regB.params[2])\n",
        "\n",
        "#Remove min and max values\n",
        "gamma0DistTable3A.sort()\n",
        "gamma0DistTable3A = gamma0DistTable3A[1 : -1]\n",
        "gamma1DistTable3A.sort()\n",
        "gamma1DistTable3A = gamma1DistTable3A[1 : -1]\n",
        "gamma2DistTable3A.sort()\n",
        "gamma2DistTable3A = gamma2DistTable3A[1 : -1]\n",
        "gamma0DistTable3B.sort()\n",
        "gamma0DistTable3B = gamma0DistTable3B[1 : -1]\n",
        "gamma1DistTable3B.sort()\n",
        "gamma1DistTable3B = gamma1DistTable3B[1 : -1]\n",
        "gamma2DistTable3B.sort()\n",
        "gamma2DistTable3B = gamma2DistTable3B[1 : -1]\n",
        "\n",
        "#Print Table 3A results\n",
        "print(\"Table 3A\")\n",
        "print(\"Pooled Regressions\")\n",
        "print(table3ARegSummary)\n",
        "print(\"Industry Level Regressions\")\n",
        "print(\"Mean - gamma_0: \" + str(np.average(gamma0DistTable3A)) + \" gamma_1: \" + str(np.average(gamma1DistTable3A)) + \" gamma_2: \" + str(np.average(gamma2DistTable3A)))\n",
        "print(\"Q1 - gamma_0: \" + str(np.quantile(gamma0DistTable3A, 0.25)) + \" gamma_1: \" + str(np.quantile(gamma1DistTable3A, 0.25)) + \" gamma_2: \" + str(np.quantile(gamma2DistTable3A, 0.25)))\n",
        "print(\"Median - gamma_0: \" + str(np.median(gamma0DistTable3A)) + \" gamma_1: \" + str(np.median(gamma1DistTable3A)) + \" gamma_2: \" + str(np.median(gamma2DistTable3A)))\n",
        "print(\"Q3 - gamma_0: \" + str(np.quantile(gamma0DistTable3A, 0.75)) + \" gamma_1: \" + str(np.quantile(gamma1DistTable3A, 0.75)) + \" gamma_2: \" + str(np.quantile(gamma2DistTable3A, 0.75)))\n",
        "\n",
        "#Print Table 3B results\n",
        "print(\"Table 3B\")\n",
        "print(\"Pooled Regressions\")\n",
        "print(table3BRegSummary)\n",
        "print(\"Industry Level Regressions\")\n",
        "print(\"Mean - gamma_0: \" + str(np.average(gamma0DistTable3B)) + \" gamma_1: \" + str(np.average(gamma1DistTable3B)) + \" gamma_2: \" + str(np.average(gamma2DistTable3B)))\n",
        "print(\"Q1 - gamma_0: \" + str(np.quantile(gamma0DistTable3B, 0.25)) + \" gamma_1: \" + str(np.quantile(gamma1DistTable3B, 0.25)) + \" gamma_2: \" + str(np.quantile(gamma2DistTable3B, 0.255)))\n",
        "print(\"Median - gamma_0: \" + str(np.median(gamma0DistTable3B)) + \" gamma_1: \" + str(np.median(gamma1DistTable3B)) + \" gamma_2: \" + str(np.median(gamma2DistTable3B)))\n",
        "print(\"Q3 - gamma_0: \" + str(np.quantile(gamma0DistTable3B, 0.75)) + \" gamma_1: \" + str(np.quantile(gamma1DistTable3B, 0.75)) + \" gamma_2: \" + str(np.quantile(gamma2DistTable3B, 0.75)))"
      ],
      "metadata": {
        "id": "ygMeONuPbFKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cvbq8oSRbFH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g2Zk1ZrAbFFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ovWuZ19IbFAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "krwCJm_ubE4F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}